Image captioning 


This project is a way through which we train a model so that that model defines a caption based on the image.

This Project is an Thorough representation of the research paper - https://arxiv.org/pdf/1411.4555.pdf

In this project we basically use an encoder and a decoder to train our model.
encoder and decoder are thoroughly implemented and trained.

The data used is COCO data set- It consist of a wide variety of realtime images and captions.

ENCODER- CNN
RESNET 50 is used in the CNN architecture as an encoder to encode wide variety of images.

DECODER - RNN
LSTM(long short term memory) is used to train and decode images to form captions from it.

This model if trained on wide range of GPU cores can turn out to have a very decent accuracy thus giving quick insights about the data.


